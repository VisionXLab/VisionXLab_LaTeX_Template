\section{Experiments}
\label{sec:experiments}

% 本章节展示实验设置和结果，包含多种类型的表格和图表

In this section, we evaluate our proposed method through comprehensive experiments. We first describe the experimental setup in Section~\ref{subsec:setup}, followed by quantitative results in Section~\ref{subsec:quantitative} and qualitative analysis in Section~\ref{subsec:qualitative}. Finally, we present ablation studies in Section~\ref{subsec:ablation}.

% 实验设置
\subsection{Experimental Setup}
\label{subsec:setup}

\paragraph{Datasets}
We evaluate our method on [number] widely-used benchmarks:
\begin{itemize}
\item \textbf{Dataset 1}~\cite{dataset1}: Contains [number] samples with [characteristics]. We follow the standard split of [train/val/test].
\item \textbf{Dataset 2}~\cite{dataset2}: A challenging dataset featuring [characteristics]. We use [number] samples for training and [number] for testing.
\item \textbf{Dataset 3}~\cite{dataset3}: Designed for [specific task], consisting of [description].
\end{itemize}

\paragraph{Evaluation Metrics}
Following prior work~\cite{baseline2022paper}, we use the following metrics:
\begin{itemize}
\item \textbf{Metric 1}: Measures [what it measures]
\item \textbf{Metric 2}: Evaluates [what it evaluates]
\item \textbf{Metric 3}: Quantifies [what it quantifies]
\end{itemize}

\paragraph{Baselines}
We compare our method against several state-of-the-art approaches:
\begin{itemize}
\item \textbf{Method A}~\cite{methoda}: [Brief description]
\item \textbf{Method B}~\cite{methodb}: [Brief description]
\item \textbf{Method C}~\cite{methodc}: [Brief description]
\item \textbf{Method D}~\cite{methodd}: [Brief description]
\end{itemize}

\paragraph{Implementation Details}
We implement our method using PyTorch and train on 4 NVIDIA A100 GPUs. The model is optimized using AdamW with a learning rate of $2 \times 10^{-4}$ and weight decay of $0.01$. We train for 100 epochs with batch size 32. Data augmentation includes random cropping, horizontal flipping, and color jittering.

% 定量结果
\subsection{Quantitative Results}
\label{subsec:quantitative}

% 主要结果表格
\begin{table*}[!tb]
\centering
\caption{Quantitative comparison on three benchmarks. Best results are in \textbf{bold}, and second best are \underline{underlined}. $\uparrow$ indicates higher is better, $\downarrow$ indicates lower is better.}
\label{tab:main_results}
\tablestyle{6pt}{1.3}
\begin{tabular}{l|ccc|ccc|ccc}
\toprule
\multirow{2}{*}{\textbf{Method}} & \multicolumn{3}{c|}{\textbf{Dataset 1}} & \multicolumn{3}{c|}{\textbf{Dataset 2}} & \multicolumn{3}{c}{\textbf{Dataset 3}} \\
& Metric1$\uparrow$ & Metric2$\uparrow$ & Metric3$\downarrow$ & Metric1$\uparrow$ & Metric2$\uparrow$ & Metric3$\downarrow$ & Metric1$\uparrow$ & Metric2$\uparrow$ & Metric3$\downarrow$ \\
\midrule
Method A~\cite{methoda} & 72.3 & 68.5 & 0.245 & 65.8 & 62.1 & 0.312 & 70.2 & 66.8 & 0.278 \\
Method B~\cite{methodb} & 75.6 & 71.2 & 0.223 & 68.4 & 65.3 & 0.289 & 73.5 & 69.7 & 0.251 \\
Method C~\cite{methodc} & 78.1 & 73.8 & 0.208 & 71.2 & 68.6 & 0.267 & 76.3 & 72.4 & 0.234 \\
Method D~\cite{methodd} & \underline{80.5} & \underline{76.3} & \underline{0.195} & \underline{74.6} & \underline{71.2} & \underline{0.248} & \underline{79.1} & \underline{75.6} & \underline{0.219} \\
\midrule
\textbf{Ours} & \textbf{83.7} & \textbf{79.8} & \textbf{0.178} & \textbf{77.9} & \textbf{74.5} & \textbf{0.231} & \textbf{82.4} & \textbf{78.9} & \textbf{0.203} \\
\bottomrule
\end{tabular}
\end{table*}

Table~\ref{tab:main_results} presents the quantitative comparison on three benchmarks. Our method consistently outperforms all baselines across all datasets and metrics. Specifically, compared to the best baseline (Method D), our approach achieves:
\begin{itemize}
\item \textbf{Dataset 1}: +3.2\% on Metric1, +3.5\% on Metric2, and -8.7\% on Metric3
\item \textbf{Dataset 2}: +3.3\% on Metric1, +3.3\% on Metric2, and -6.9\% on Metric3
\item \textbf{Dataset 3}: +3.3\% on Metric1, +3.3\% on Metric2, and -7.3\% on Metric3
\end{itemize}

These improvements demonstrate the effectiveness of our proposed components, particularly [Component X] which addresses [specific limitation of baselines].

% 不同设置下的结果
\begin{table}[!tb]
\centering
\caption{Performance under different settings on Dataset 1. Our method maintains robust performance across various conditions.}
\label{tab:different_settings}
\tablestyle{4pt}{1.2}
\begin{tabular}{lcccc}
\toprule
\textbf{Setting} & \textbf{Baseline} & \textbf{Method D} & \textbf{Ours} & \textbf{Gain} \\
\midrule
Standard & 75.6 & 80.5 & \textbf{83.7} & +3.2 \\
Low-resource & 68.2 & 72.8 & \textbf{76.4} & +3.6 \\
High-noise & 62.5 & 67.3 & \textbf{71.1} & +3.8 \\
Cross-domain & 58.9 & 63.7 & \textbf{68.2} & +4.5 \\
\bottomrule
\end{tabular}
\end{table}

% 定性结果
\subsection{Qualitative Results}
\label{subsec:qualitative}

% 示例比较图
\begin{figure}[!tb]
\centering
\includegraphics[width=0.6\linewidth]{figures/content/qualitative_comparison.pdf}
\caption{\textbf{Qualitative comparison with baseline methods.} From left to right: Input, Ground Truth, Method B, Method D, and Ours. Our method produces results that are more [describe advantages], particularly in [challenging scenarios]. Red boxes highlight regions where our method shows significant improvements.}
\label{fig:qualitative}
\end{figure}

Figure~\ref{fig:qualitative} shows qualitative comparisons between our method and baselines. As can be observed, our approach generates more [quality attribute] results, especially in challenging cases involving [difficult scenarios]. While Method D performs reasonably well in [certain aspects], it struggles with [specific challenges]. In contrast, our method successfully handles these cases by [explain why your method works].

% 消融实验
\subsection{Ablation Study}
\label{subsec:ablation}

% 消融实验表格
\begin{table}[!tb]
\centering
\caption{Ablation study on Dataset 1. Each row removes one component from the full model to analyze its contribution.}
\label{tab:ablation}
\tablestyle{4pt}{1.2}
\begin{tabular}{lccc}
\toprule
\textbf{Variant} & \textbf{Metric1$\uparrow$} & \textbf{Metric2$\uparrow$} & \textbf{Metric3$\downarrow$} \\
\midrule
Full Model & \textbf{83.7} & \textbf{79.8} & \textbf{0.178} \\
\midrule
w/o Component 1 & 79.2 & 75.4 & 0.201 \\
w/o Component 2 & 80.8 & 77.1 & 0.189 \\
w/o Component 3 & 81.5 & 78.2 & 0.184 \\
w/o Loss Term 1 & 82.1 & 78.6 & 0.182 \\
w/o Loss Term 2 & 82.9 & 79.2 & 0.180 \\
\bottomrule
\end{tabular}
\end{table}

To validate the effectiveness of each component, we conduct ablation studies by removing individual components from the full model. As shown in Table~\ref{tab:ablation}, each component contributes to the overall performance:

\begin{itemize}
\item \textbf{Component 1} has the largest impact (-4.5\% on Metric1), confirming its importance for [its role].
\item \textbf{Component 2} contributes -2.9\% on Metric1, demonstrating its value in [its purpose].
\item \textbf{Component 3} provides -2.2\% improvement, showing that [its benefit].
\item Both loss terms contribute to performance, with Loss Term 1 being more critical.
\end{itemize}

% 超参数分析
\subsection{Hyperparameter Analysis}
\label{subsec:hyperparameter}

\begin{figure}[!tb]
\centering
\includegraphics[width=0.6\linewidth]{figures/content/hyperparameter_analysis.pdf}
\caption{\textbf{Impact of key hyperparameters.} We analyze the effect of (left) $\lambda_1$ and (right) $\lambda_2$ on performance. The model is relatively robust to hyperparameter choices within reasonable ranges.}
\label{fig:hyperparameter}
\end{figure}

We analyze the sensitivity of our method to key hyperparameters. As shown in Figure~\ref{fig:hyperparameter}, performance is relatively stable across a wide range of $\lambda_1$ and $\lambda_2$ values, indicating that our method is robust and does not require extensive hyperparameter tuning. The optimal performance is achieved when $\lambda_1 = 0.1$ and $\lambda_2 = 0.5$.
